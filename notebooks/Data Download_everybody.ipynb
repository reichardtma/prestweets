{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a0e01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snscrape\n",
      "  Downloading snscrape-0.4.3.20220106-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: pytz in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from snscrape) (2022.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from snscrape) (4.10.0)\n",
      "Requirement already satisfied: requests[socks] in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from snscrape) (2.27.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from beautifulsoup4->snscrape) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from requests[socks]->snscrape) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from requests[socks]->snscrape) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from requests[socks]->snscrape) (2.0.12)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: PySocks, lxml, filelock, snscrape\n",
      "Successfully installed PySocks-1.7.1 filelock-3.6.0 lxml-4.8.0 snscrape-0.4.3.20220106\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5898af63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep_translator\n",
      "  Downloading deep_translator-1.8.1-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from deep_translator) (4.10.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from deep_translator) (2.27.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/reichardtma/.pyenv/versions/3.8.12/envs/prestweets/lib/python3.8/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.26.9)\n",
      "Installing collected packages: deep_translator\n",
      "Successfully installed deep_translator-1.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip install deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c1aad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from deep_translator import (GoogleTranslator,\n",
    "                             PonsTranslator,\n",
    "                             LingueeTranslator,\n",
    "                             MyMemoryTranslator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9edfd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = [\"jokowi\", \"jairbolsonaro\", \"borisjohnson\", \"CyrilRamaphosa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f10bd459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweets(username):\n",
    "    data = None\n",
    "\n",
    "    os.system(\n",
    "            f'snscrape --jsonl --progress twitter-user {username} > twitter-@{username}.json')\n",
    "\n",
    "    tweets_df = pd.read_json(f'twitter-@{username}.json', lines=True)\n",
    "    df = tweets_df[[\"id\", \"url\", \"date\", \"content\",\n",
    "                        \"hashtags\", \"cashtags\", \"media\", \"lang\"]]\n",
    "    if data is None:\n",
    "        data = df\n",
    "    else:\n",
    "        data = data.append(df)\n",
    "        \n",
    "    #Translate the tweets\n",
    "    if df.lang[0] != \"en\" and df.lang[27] != \"en\":\n",
    "        df['Translation'] = df.apply(lambda row: GoogleTranslator(source='auto', target='english').translate(text=f'{row.content}'), axis=1)\n",
    "    \n",
    "    #Save as csv file\n",
    "    df.to_csv(f\"{username}_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "195d464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping, 100 results so far\n",
      "Scraping, 200 results so far\n",
      "Scraping, 300 results so far\n",
      "Scraping, 400 results so far\n",
      "Scraping, 500 results so far\n",
      "Scraping, 600 results so far\n",
      "Scraping, 700 results so far\n",
      "Scraping, 800 results so far\n",
      "Scraping, 900 results so far\n",
      "Scraping, 1000 results so far\n",
      "Scraping, 1100 results so far\n",
      "Scraping, 1200 results so far\n",
      "Scraping, 1300 results so far\n",
      "Scraping, 1400 results so far\n",
      "Scraping, 1500 results so far\n",
      "Scraping, 1600 results so far\n",
      "Scraping, 1700 results so far\n",
      "Scraping, 1800 results so far\n",
      "Scraping, 1900 results so far\n",
      "Scraping, 2000 results so far\n",
      "Scraping, 2100 results so far\n",
      "Scraping, 2200 results so far\n",
      "Scraping, 2300 results so far\n",
      "Scraping, 2400 results so far\n",
      "Scraping, 2500 results so far\n",
      "Scraping, 2600 results so far\n",
      "Scraping, 2700 results so far\n",
      "Scraping, 2800 results so far\n",
      "Scraping, 2900 results so far\n",
      "Scraping, 3000 results so far\n",
      "Scraping, 3100 results so far\n",
      "Scraping, 3200 results so far\n",
      "Scraping, 3300 results so far\n",
      "Scraping, 3400 results so far\n",
      "Scraping, 3500 results so far\n",
      "Scraping, 3600 results so far\n",
      "Scraping, 3700 results so far\n",
      "Scraping, 3800 results so far\n",
      "Scraping, 3900 results so far\n",
      "Scraping, 4000 results so far\n",
      "Scraping, 4100 results so far\n",
      "Scraping, 4200 results so far\n",
      "Scraping, 4300 results so far\n",
      "Scraping, 4400 results so far\n",
      "Scraping, 4500 results so far\n",
      "Scraping, 4600 results so far\n",
      "Scraping, 4700 results so far\n",
      "Scraping, 4800 results so far\n",
      "Scraping, 4900 results so far\n",
      "Scraping, 5000 results so far\n",
      "Scraping, 5100 results so far\n",
      "Scraping, 5200 results so far\n",
      "Scraping, 5300 results so far\n",
      "Scraping, 5400 results so far\n",
      "Scraping, 5500 results so far\n",
      "Scraping, 5600 results so far\n",
      "Scraping, 5700 results so far\n",
      "Scraping, 5800 results so far\n",
      "Scraping, 5900 results so far\n",
      "Scraping, 6000 results so far\n",
      "Scraping, 6100 results so far\n",
      "Scraping, 6200 results so far\n",
      "Scraping, 6300 results so far\n",
      "Scraping, 6400 results so far\n",
      "Scraping, 6500 results so far\n",
      "Scraping, 6600 results so far\n",
      "Scraping, 6700 results so far\n",
      "Scraping, 6800 results so far\n",
      "Scraping, 6900 results so far\n",
      "Scraping, 7000 results so far\n",
      "Scraping, 7100 results so far\n",
      "Scraping, 7200 results so far\n",
      "Scraping, 7300 results so far\n",
      "Scraping, 7400 results so far\n",
      "Scraping, 7500 results so far\n",
      "Scraping, 7600 results so far\n",
      "Scraping, 7700 results so far\n",
      "Scraping, 7800 results so far\n",
      "Scraping, 7900 results so far\n",
      "Scraping, 8000 results so far\n",
      "Scraping, 8100 results so far\n",
      "Scraping, 8200 results so far\n",
      "Scraping, 8300 results so far\n",
      "Scraping, 8400 results so far\n",
      "Scraping, 8500 results so far\n",
      "Scraping, 8600 results so far\n",
      "Scraping, 8700 results so far\n",
      "Scraping, 8800 results so far\n",
      "Scraping, 8900 results so far\n",
      "Scraping, 9000 results so far\n",
      "Scraping, 9100 results so far\n",
      "Scraping, 9200 results so far\n",
      "Scraping, 9300 results so far\n",
      "Scraping, 9400 results so far\n",
      "Scraping, 9500 results so far\n",
      "Scraping, 9600 results so far\n",
      "Scraping, 9700 results so far\n",
      "Scraping, 9800 results so far\n",
      "Scraping, 9900 results so far\n",
      "Scraping, 10000 results so far\n",
      "Scraping, 10100 results so far\n",
      "Scraping, 10200 results so far\n",
      "Scraping, 10300 results so far\n",
      "Scraping, 10400 results so far\n",
      "Finished, 10417 results\n",
      "/tmp/ipykernel_3259/4031179089.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Translation'] = df.apply(lambda row: GoogleTranslator(source='auto', target='english').translate(text=f'{row.content}'), axis=1)\n",
      "Scraping, 100 results so far\n",
      "Scraping, 200 results so far\n",
      "Scraping, 300 results so far\n",
      "Scraping, 400 results so far\n",
      "Scraping, 500 results so far\n",
      "Scraping, 600 results so far\n",
      "Scraping, 700 results so far\n",
      "Scraping, 800 results so far\n",
      "Scraping, 900 results so far\n",
      "Scraping, 1000 results so far\n",
      "Scraping, 1100 results so far\n",
      "Scraping, 1200 results so far\n",
      "Scraping, 1300 results so far\n",
      "Scraping, 1400 results so far\n",
      "Scraping, 1500 results so far\n",
      "Scraping, 1600 results so far\n",
      "Scraping, 1700 results so far\n",
      "Scraping, 1800 results so far\n",
      "Scraping, 1900 results so far\n",
      "Scraping, 2000 results so far\n",
      "Scraping, 2100 results so far\n",
      "Scraping, 2200 results so far\n",
      "Scraping, 2300 results so far\n",
      "Scraping, 2400 results so far\n",
      "Scraping, 2500 results so far\n",
      "Scraping, 2600 results so far\n",
      "Scraping, 2700 results so far\n",
      "Scraping, 2800 results so far\n",
      "Scraping, 2900 results so far\n",
      "Scraping, 3000 results so far\n",
      "Scraping, 3100 results so far\n",
      "Scraping, 3200 results so far\n",
      "Scraping, 3300 results so far\n",
      "Scraping, 3400 results so far\n",
      "Scraping, 3500 results so far\n",
      "Scraping, 3600 results so far\n",
      "Scraping, 3700 results so far\n",
      "Scraping, 3800 results so far\n",
      "Scraping, 3900 results so far\n",
      "Scraping, 4000 results so far\n",
      "Finished, 4075 results\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for username in usernames:\n",
    "    save_tweets(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc9bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
